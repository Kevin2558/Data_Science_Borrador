# Tarea 2, parte 1 â€” ReducciÃ³n de Dimensionalidad (solo pre-procesamiento)

> **Objetivo:** practicar distintas tÃ©cnicas de reducciÃ³n de variables  

---

## Instrucciones generales

1. Descarga el dataset indicado desde Kaggle.  
2. Carga los datos en un notebook (`pandas`) e inspecciona su forma *(filas Ã— columnas)*.  
3. Estandariza las variables numÃ©ricas cuando corresponda (`StandardScaler`).  
4. Aplica la tÃ©cnica de reducciÃ³n solicitada.  
5. Reporta en tu notebook:  
   - **NÃºmero de componentes** retenidos.  
   - **Porcentaje de varianza explicada** (o criterio equivalente).  
   - Una **visualizaciÃ³n 2-D** o 3-D (scatter) coloreada con la etiqueta disponible, si existe.  
   - Una breve conclusiÃ³n (2-3 frases) sobre si la proyecciÃ³n revela estructura o correlaciones.

---

## Lista de ejercicios

| # | Dataset (Kaggle slug) | Tipo / DimensiÃ³n | TÃ©cnica de reducciÃ³n solicitada |
|---|-----------------------|------------------|---------------------------------|
| 1 | `zalando-research/fashionmnist` | 70 000 Ã— 784 (imÃ¡genes) | **PCA** â†’ conservar 95 % de la varianza |
| 2 | `mchrishtw/human-activity-recognition-with-smartphones` | 10 299 Ã— 561 (sensores) | **PCA** (scree plot) + **ICA** (10 componentes); compara varianza vs. independencia |
| 3 | `wine-quality` | 6 497 Ã— 11 (quÃ­mico) | **LDA** (proyecciÃ³n supervisada) â†’ 2 componentes y scatter tintos vs. blancos |
| 4 | `credit-card-fraud` | 284 807 Ã— 30 (numÃ©rico) | **t-SNE** y **UMAP** a 2 D; colorea fraude / no fraude |
| 5 | `uci-ml/energy-efficiency` | 768 Ã— 8 (regresiÃ³n) | **PCA** a 2 D; muestra por quÃ© a veces la reducciÃ³n **no** es necesaria (varianza explicada â‰¥ 90 %?) |


# Parte 2 â€” Modelos Supervisados sobre Datos Reducidos

## ğŸ¯ Objetivo
Aplicar modelos supervisados sobre datasets con y sin reducciÃ³n de dimensionalidad, comparando su rendimiento y utilidad.

---

## ğŸ“Œ Instrucciones Generales

Para cada uno de los datasets usados en la Parte 1:

1. **Prepara los datos**:
   - Usa la versiÃ³n reducida del dataset (por PCA, ICA, LDA, etc.).
   - Si es necesario, vuelve a calcular la reducciÃ³n con `scikit-learn`.

2. **Divide el dataset** en conjuntos de entrenamiento y prueba (ej. 80/20).

3. **Entrena al menos dos modelos supervisados**:
   - Para clasificaciÃ³n: `LogisticRegression`, `KNeighborsClassifier`, `DecisionTreeClassifier`, `RandomForestClassifier`, etc.
   - Para regresiÃ³n: `LinearRegression`, `Ridge`, `RandomForestRegressor`, etc.

4. **EvalÃºa el rendimiento**:
   - ClasificaciÃ³n: `accuracy`, `precision`, `recall`, `F1-score`, `confusion_matrix`, `ROC-AUC`.
   - RegresiÃ³n: `MAE`, `RMSE`, `RÂ²`.

5. **Compara resultados**:
   - Entrena los mismos modelos usando las **features originales** (sin reducciÃ³n).
   - Compara el rendimiento con y sin reducciÃ³n de dimensionalidad.
   - Usa una tabla o resumen visual.

---

## ğŸ“Š Reporte Esperado para Cada Dataset

- âœ… CÃ³digo bien comentado y organizado.
- ğŸ“ˆ Visualizaciones o mÃ©tricas de evaluaciÃ³n.
- ğŸ“Š Tabla comparativa con rendimiento con vs. sin reducciÃ³n.
- ğŸ’¬ Mini-conclusiÃ³n: Â¿ayudÃ³ la reducciÃ³n? Â¿CuÃ¡l modelo funcionÃ³ mejor?

---

## ğŸ’¡ Sugerencias por Dataset

| Dataset                           | Tipo         | Modelos recomendados                          |
|----------------------------------|--------------|-----------------------------------------------|
| Fashion MNIST                    | ClasificaciÃ³n| Logistic Regression, SVM, k-NN                 |
| Human Activity Recognition       | ClasificaciÃ³n| Random Forest, k-NN, Gradient Boosting         |
| Wine Quality                     | ClasificaciÃ³n| Logistic Regression, k-NN, LDA                 |
| Credit Card Fraud Detection      | ClasificaciÃ³n| Logistic Regression, Random Forest             |
| Energy Efficiency (regresiÃ³n)    | RegresiÃ³n    | Linear Regression, Ridge, Random Forest        |

---

## ğŸ“ ReflexiÃ³n Final

Al final del notebook, agrega una secciÃ³n:

```markdown
## ğŸ“Œ ReflexiÃ³n General
- Â¿En quÃ© casos la reducciÃ³n de dimensionalidad **mejorÃ³ o perjudicÃ³** el rendimiento?
- Â¿QuÃ© tÃ©cnica y modelo te parecieron mÃ¡s adecuados para cada tipo de datos?
- Â¿RecomendarÃ­as aplicar reducciÃ³n de dimensionalidad antes de modelar?
```
---

Enlaces a los Datasets
Fashion MNIST (imÃ¡genes de ropa, 70,000 Ã— 784)

Kaggle: https://www.kaggle.com/datasets/zalando-research/fashionmnist

Human Activity Recognition with Smartphones (sensores, 10,299 Ã— 561)

Kaggle: https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones

Wine Quality (vino tinto y blanco, 6,497 Ã— 11)

Kaggle: https://www.kaggle.com/datasets/rajyellow46/wine-quality

Credit Card Fraud Detection (transacciones, 284,807 Ã— 30)

Kaggle: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

Energy Efficiency (regresiÃ³n, 768 Ã— 8)

Kaggle: https://www.kaggle.com/datasets/ujjwalchowdhury/energy-efficiency-data-set



### Entrega

- Notebook (.ipynb) bien comentado.  
- Incluye grÃ¡ficos y celdas con los valores de varianza explicada / independencia.  
- Una secciÃ³n final â€œConclusionesâ€ (mÃ¡x. Â½ pÃ¡gina) donde resumas quÃ© tÃ©cnica te pareciÃ³ mÃ¡s informativa para cada dataset.
