# Clasificación de objetos estelares en catálogos astronómicos (Usando MLPs)

## Descripción General

Este proyecto busca desarrollar un modelo de clasficación que sea capaz de identificar y categorizar diferentes tipos de objetos estelares (ej. estrellas, galaxias, cuásares) utilizando características numéricas extraídas de grandes catálogos astronómicos, aplicando Perceptrones Multicapa (MLPs).

## Dataset

* **Nombre del Dataset:** [Nombre completo del dataset, ej., "Fashion MNIST", "Human Activity Recognition with Smartphones"]
* **Fuente:** [Enlace directo a la fuente del dataset, ej., Kaggle, UCI Machine Learning Repository]
* **Descripción Breve:** [Una o dos oraciones que describan el contenido del dataset (número de filas, columnas, tipo de datos, qué representan las características y la variable objetivo).]

## Objetivos del Proyecto

Los principales objetivos de este proyecto fueron:

1. Obtener un dataset de objetos estelares catalogados (numéricos) y prepararlos para el modelado.
2. Aplicar reducciones de dimensionalidad para visualizaciones del dataset y/o simplificar los modelos.
3. Implementar y entrenar modelos de Machine Learning (incluyendo un MLP) para la clasificación de objetos estelares.
4. Medir el rendimiento de todos los modelos y compararlos.
5. Sintetizar los hallazgos, discutir las implicaciones del proyecto y decidir el modelo más atractivo.

## Metodología

El proceso seguido en este proyecto incluyó las siguientes etapas:

1.  **Carga y Exploración de Datos (EDA):** [Breve descripción de qué se hizo en esta etapa, ej., "análisis de distribuciones, identificación de valores atípicos/faltantes, correlaciones."]
2.  **Preprocesamiento de Datos:** [Descripción de las transformaciones aplicadas, ej., "escalado de características (StandardScaler), codificación de variables categóricas (One-Hot Encoding)."]
3.  **Reducción de Dimensionalidad:** Se utilizó [Técnica de Reducción, ej., PCA (Análisis de Componentes Principales)] para [propósito, ej., "reducir la dimensionalidad del dataset a X componentes principales para facilitar la visualización y mejorar el rendimiento del modelo"].
4.  **Modelado:** Se entrenaron y evaluaron varios modelos de Machine Learning, incluyendo:
    * [Modelo 1, ej., "Regresión Logística"]
    * [Modelo 2, ej., "Support Vector Machine (SVM)"]
    * [Modelo 3, ej., "Random Forest"]
    * [Añadir otros modelos utilizados]
5.  **Evaluación:** El rendimiento de los modelos fue evaluado utilizando métricas como [Métricas de Evaluación, ej., "Accuracy, Precision, Recall, F1-Score (para clasificación)", "MAE, RMSE, R² (para regresión)"].

## Resultados y Conclusiones Clave

* [Conclusión 1: Ej. "PCA logró capturar el 95% de la varianza con solo X componentes, facilitando la visualización."]
* [Conclusión 2: Ej. "El modelo [Nombre del Modelo] obtuvo el mejor rendimiento con [métrica clave] de [valor] en este dataset."]
* [Conclusión 3: Ej. "La reducción de dimensionalidad [mejoró/empeoró/no afectó significativamente] el rendimiento del modelo, pero [razón, ej., "redujo el tiempo de entrenamiento"]."]
* [Conclusión 4: Ej. "Los desafíos encontrados incluyeron [desafío, ej., "el desequilibrio de clases", "la alta dimensionalidad"] y cómo se abordaron."]

## Tecnologías y Librerías Utilizadas

* Python [Versión]
* `pandas`
* `numpy`
* `scikit-learn`
* `matplotlib`
* `seaborn`
* [Añadir cualquier otra librería específica, ej., `tensorflow`, `keras`, `imblearn`]

## Autor

* **Almendra Orellana, Kevin Ortiz y Jorge Pastene**
* [Tu Perfil de GitHub (enlace)]
* [Tu Perfil de LinkedIn (enlace)]

---
